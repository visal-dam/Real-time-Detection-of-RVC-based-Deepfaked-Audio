{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc6811-49ca-4f78-8211-95d62982f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "cd /content/drive/MyDrive/332_5-2_HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7341ef0a-fd6d-4aaf-b84b-a134c1fff9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/RVC-Project/Retrieval-based-Voice-Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956db17b-df6f-4693-b6b9-c960e5a3c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rvc.modules.vc.modules import VC\n",
    "from dotenv import load_dotenv\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7501a-3ddb-49ee-a35d-46ebfe12ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"/content/drive/MyDrive/332_5-2_HD/.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a4936-fb98-455f-8a8b-4a57f7ea981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rvc_audio(model_path, input_speech_path, output_speech_path):\n",
    "  load_dotenv(\"/content/drive/MyDrive/332_5-2_HD/.env\", override=True)\n",
    "  vc = VC()\n",
    "  vc.get_vc(Path(model_path))\n",
    "  tgt_sr, audio_opt, times, _ = vc.vc_inference(1, input_speech_path)\n",
    "  wavfile.write(output_speech_path, tgt_sr, audio_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c932fb-44c4-48d4-af1b-00266f45d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvc_audio(\"/content/drive/MyDrive/332_5-2_HD/models/lumine/lumine.pth\",\n",
    "          \"/content/drive/MyDrive/332_5-2_HD/real/visal.wav\",\n",
    "          \"/content/drive/MyDrive/332_5-2_HD/fake/visal-lumine.wav\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d6b7d-ae2f-483c-824c-65015c428b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_(input_audio_path):\n",
    "    #y, sr = librosa.load(input_audio_path, sr=None)\n",
    "    y = AudioSegment.from_wav(input_audio_path)\n",
    "    x = y.get_array_of_samples() \n",
    "    sr = y.frame_rate\n",
    "    print(\"sr: \", sr)\n",
    "    block_length = sr # 48000 samples = 1 second\n",
    "    overlap_constant = 0.6354\n",
    "    hop_length = int(sr * overlap_constant)\n",
    "    duration = 600\n",
    "\n",
    "    print(f\"Audio length: {duration} seconds\")\n",
    "\n",
    "    num_blocks = int(duration / overlap_constant) - 1\n",
    "    features = []\n",
    "\n",
    "    for i in range(num_blocks): # for every 48000 samples\n",
    "        start = i * hop_length\n",
    "        end = start + block_length\n",
    "        block = x[start:end]\n",
    "\n",
    "        chroma = librosa.feature.chroma_stft(y=np.float32(block), sr=sr)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        #print(chroma_mean)\n",
    "        features.append(chroma_mean)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f8777-ab04-4d56-a1bf-9507a7de3ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features__(input_audio_path):\n",
    "    y, sr = librosa.load(input_audio_path, sr=16000)\n",
    "    print(\"sr: \", sr)\n",
    "    block_length = sr # 48000 samples = 1 second\n",
    "    overlap_constant = 0.6354\n",
    "    hop_length = int(sr * overlap_constant)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "    print(f\"Audio length: {duration} seconds\")\n",
    "\n",
    "    num_blocks = int(duration / overlap_constant) - 1\n",
    "    features = []\n",
    "\n",
    "    for i in range(num_blocks): # for every 48000 samples\n",
    "        start = i * hop_length\n",
    "        end = start + block_length\n",
    "        block = y[start:end]\n",
    "\n",
    "        rms = librosa.feature.rms(y=block)\n",
    "        features.append(rms)\n",
    "        print(rms)\n",
    "\n",
    "    return np.array(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
